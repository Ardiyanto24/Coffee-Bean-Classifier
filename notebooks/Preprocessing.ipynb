{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa66b1a5",
   "metadata": {
    "papermill": {
     "duration": 0.004723,
     "end_time": "2026-02-20T07:20:13.583834",
     "exception": false,
     "start_time": "2026-02-20T07:20:13.579111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚òï Coffee Bean Quality Classification\n",
    "## Stage 1 ‚Äî Preprocessing\n",
    "\n",
    "---\n",
    "\n",
    "> **‚ÑπÔ∏è Catatan Arsitektur**\n",
    "> Semua class (`DuplicateDetector`, `LabelProcessor`, `DataSplitter`,\n",
    "> `PreprocessingPipeline`) sudah dipindahkan ke `src/` di repository GitHub.\n",
    "> Notebook ini hanya berisi konfigurasi, eksekusi pipeline, dan inspeksi hasil.\n",
    ">\n",
    "> Output notebook ini (CSV splits) adalah input untuk `02_modeling_baseline.ipynb`.\n",
    "\n",
    "---\n",
    "\n",
    "### Pipeline Overview\n",
    "\n",
    "```\n",
    "Step 1 ‚Äî Load metadata CSV & resolve image paths\n",
    "Step 2 ‚Äî Remove exact duplicates  (MD5)\n",
    "Step 3 ‚Äî Remove near-duplicates   (64-bit pHash, Hamming ‚â§ 4)\n",
    "Step 4 ‚Äî Encode labels            (sklearn LabelEncoder)\n",
    "Step 5 ‚Äî Group-Aware Stratified Split (train / val / test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66d87a0",
   "metadata": {
    "papermill": {
     "duration": 0.005549,
     "end_time": "2026-02-20T07:20:13.593298",
     "exception": false,
     "start_time": "2026-02-20T07:20:13.587749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## üì¶ 1. Clone Repository & Install Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf1faa48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T07:20:13.602407Z",
     "iopub.status.busy": "2026-02-20T07:20:13.601880Z",
     "iopub.status.idle": "2026-02-20T07:20:26.078529Z",
     "shell.execute_reply": "2026-02-20T07:20:26.077411Z"
    },
    "papermill": {
     "duration": 12.483976,
     "end_time": "2026-02-20T07:20:26.080758",
     "exception": false,
     "start_time": "2026-02-20T07:20:13.596782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Coffee-Bean-Classifier'...\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 76, in resolve\n",
      "    collected = self.factory.collect_root_requirements(root_reqs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 538, in collect_root_requirements\n",
      "    reqs = list(\n",
      "           ^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 494, in _make_requirements_from_install_req\n",
      "    cand = self._make_base_candidate_from_link(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 210, in _make_base_candidate_from_link\n",
      "    self._editable_candidate_cache[link] = EditableCandidate(\n",
      "                                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 328, in __init__\n",
      "    super().__init__(\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n",
      "    self.dist = self._prepare()\n",
      "                ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 235, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 338, in _prepare_distribution\n",
      "    return self._factory.preparer.prepare_editable_requirement(self._ireq)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/prepare.py\", line 698, in prepare_editable_requirement\n",
      "    dist = _get_prepared_distribution(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/prepare.py\", line 72, in _get_prepared_distribution\n",
      "    abstract_dist.prepare_distribution_metadata(\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/distributions/sdist.py\", line 54, in prepare_distribution_metadata\n",
      "    self.req.isolated_editable_sanity_check()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/req/req_install.py\", line 540, in isolated_editable_sanity_check\n",
      "    and not self.supports_pyproject_editable\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/functools.py\", line 998, in __get__\n",
      "    val = self.func(instance)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/req/req_install.py\", line 257, in supports_pyproject_editable\n",
      "    return \"build_editable\" in self.pep517_backend._supported_features()\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 153, in _supported_features\n",
      "    return self._call_hook('_supported_features', {})\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 321, in _call_hook\n",
      "    raise BackendUnavailable(data.get('traceback', ''))\n",
      "pip._vendor.pyproject_hooks._impl.BackendUnavailable: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 77, in _build_backend\n",
      "    obj = import_module(mod_path)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1324, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'setuptools.backends'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Repository siap.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# Clone repo dari GitHub dan install sebagai package\n",
    "REPO_URL = \"https://github.com/Ardiyanto24/Coffee-Bean-Classifier.git\"\n",
    "REPO_DIR = \"Coffee-Bean-Classifier\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    os.system(f\"git clone {REPO_URL}\")\n",
    "else:\n",
    "    # Jika sudah ada, pull update terbaru\n",
    "    os.system(f\"git -C {REPO_DIR} pull\")\n",
    "\n",
    "# Install sebagai editable package agar src/ bisa di-import\n",
    "os.system(f\"pip install -e {REPO_DIR} -q\")\n",
    "os.system(f\"pip install imagehash -q\")\n",
    "\n",
    "# Tambahkan root repo ke sys.path sebagai fallback\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "print(\"‚úÖ Repository siap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38e9454",
   "metadata": {
    "papermill": {
     "duration": 0.003789,
     "end_time": "2026-02-20T07:20:26.089121",
     "exception": false,
     "start_time": "2026-02-20T07:20:26.085332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## üìö 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d9b910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T07:20:26.101487Z",
     "iopub.status.busy": "2026-02-20T07:20:26.100510Z",
     "iopub.status.idle": "2026-02-20T07:20:28.702080Z",
     "shell.execute_reply": "2026-02-20T07:20:28.701153Z"
    },
    "papermill": {
     "duration": 2.609385,
     "end_time": "2026-02-20T07:20:28.704495",
     "exception": false,
     "start_time": "2026-02-20T07:20:26.095110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2526e2df",
   "metadata": {
    "papermill": {
     "duration": 0.003771,
     "end_time": "2026-02-20T07:20:28.712171",
     "exception": false,
     "start_time": "2026-02-20T07:20:28.708400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## üì¶ 3. Import dari `src/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36836a3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T07:20:28.722263Z",
     "iopub.status.busy": "2026-02-20T07:20:28.721221Z",
     "iopub.status.idle": "2026-02-20T07:20:28.735364Z",
     "shell.execute_reply": "2026-02-20T07:20:28.734390Z"
    },
    "papermill": {
     "duration": 0.021429,
     "end_time": "2026-02-20T07:20:28.737347",
     "exception": false,
     "start_time": "2026-02-20T07:20:28.715918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Semua class berhasil di-import dari src/\n"
     ]
    }
   ],
   "source": [
    "from src.config import PreprocessingConfig\n",
    "from src.data.preprocessing import (\n",
    "    DuplicateDetector,\n",
    "    LabelProcessor,\n",
    "    DataSplitter,\n",
    "    PreprocessingPipeline,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Semua class berhasil di-import dari src/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b058cc4a",
   "metadata": {
    "papermill": {
     "duration": 0.003812,
     "end_time": "2026-02-20T07:20:28.745103",
     "exception": false,
     "start_time": "2026-02-20T07:20:28.741291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## ‚öôÔ∏è 4. Configuration Setup\n",
    "\n",
    "Edit nilai di bawah sesuai path dataset Anda di Kaggle.\n",
    "\n",
    "| Parameter | Keterangan |\n",
    "|-----------|------------|\n",
    "| `metadata_path` | Path ke CSV metadata yang berisi kolom `filepath` dan `label` |\n",
    "| `image_base_dir` | Root folder gambar ‚Äî digunakan untuk resolve path relatif |\n",
    "| `phash_hash_size` | Ukuran grid DCT (default 8 = 64-bit hash, jangan diubah) |\n",
    "| `phash_threshold` | Hamming distance cutoff near-duplicate (default 4, standar) |\n",
    "| `val_size` / `test_size` | Proporsi split validasi dan test |\n",
    "| `output_dir` | Folder output untuk menyimpan CSV splits |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "947c8a8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T07:20:28.755188Z",
     "iopub.status.busy": "2026-02-20T07:20:28.754825Z",
     "iopub.status.idle": "2026-02-20T07:20:28.760522Z",
     "shell.execute_reply": "2026-02-20T07:20:28.759554Z"
    },
    "papermill": {
     "duration": 0.013432,
     "end_time": "2026-02-20T07:20:28.762578",
     "exception": false,
     "start_time": "2026-02-20T07:20:28.749146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = PreprocessingConfig(\n",
    "    metadata_path   = '/kaggle/input/datasets/arproject01/metadata/coffee_metadata.csv',\n",
    "    image_base_dir  = '/kaggle/input/datasets/ardiyanto24/coffee-bean-classification-dataset/Deteksi Jenis Kopi/train',\n",
    "    phash_hash_size = 8,   # 8x8 DCT ‚Üí 64-bit hash (standard, do not change)\n",
    "    phash_threshold = 4,   # Hamming distance <= 4 (standard for 64-bit pHash)\n",
    "    val_size        = 0.15,\n",
    "    test_size       = 0.15,\n",
    "    random_state    = 42,\n",
    "    path_col        = 'filepath',\n",
    "    label_col       = 'label',\n",
    "    save_splits     = True,\n",
    "    output_dir      = '/kaggle/working/preprocessed'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1455820b",
   "metadata": {
    "papermill": {
     "duration": 0.003745,
     "end_time": "2026-02-20T07:20:28.770576",
     "exception": false,
     "start_time": "2026-02-20T07:20:28.766831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## ‚ñ∂Ô∏è 5. Run Preprocessing\n",
    "\n",
    "Dua opsi tersedia:\n",
    "\n",
    "| Opsi | Kapan Digunakan |\n",
    "|------|-----------------|\n",
    "| **Option A** ‚Äî Full Pipeline | Jalankan semua step sekaligus (recommended) |\n",
    "| **Option B** ‚Äî Step-by-Step | Jalankan per step jika butuh kontrol lebih detail |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041cb16e",
   "metadata": {
    "papermill": {
     "duration": 0.003623,
     "end_time": "2026-02-20T07:20:28.777841",
     "exception": false,
     "start_time": "2026-02-20T07:20:28.774218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ‚ñ∂Ô∏è Option A ‚Äî Full Pipeline *(Recommended)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b74f747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T07:20:28.787134Z",
     "iopub.status.busy": "2026-02-20T07:20:28.786653Z",
     "iopub.status.idle": "2026-02-20T07:20:46.952741Z",
     "shell.execute_reply": "2026-02-20T07:20:46.951677Z"
    },
    "papermill": {
     "duration": 18.173485,
     "end_time": "2026-02-20T07:20:46.954956",
     "exception": false,
     "start_time": "2026-02-20T07:20:28.781471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Loading metadata from: /kaggle/input/datasets/arproject01/metadata/coffee_metadata.csv\n",
      "[INFO] Metadata loaded: 1211 valid records.\n",
      "[INFO] === Duplicate Detection Started ===\n",
      "[INFO] [1/2] Computing MD5 hashes for exact duplicate detection...\n",
      "[INFO]     Exact duplicates removed : 11\n",
      "[INFO]     Remaining records        : 1200\n",
      "[INFO] [2/2] Computing 64-bit pHash (DCT) for near-duplicate detection...\n",
      "[INFO]     Hash size  : 8x8 = 64-bit\n",
      "[INFO]     Threshold  : Hamming distance <= 4\n",
      "[INFO]     Near-duplicates removed : 73\n",
      "[INFO]     Remaining records       : 1127\n",
      "[INFO] === Duplicate Detection Completed ===\n",
      "[INFO] Classes found (4): ['defect', 'longberry', 'peaberry', 'premium']\n",
      "[INFO] Mapping: {'defect': 0, 'longberry': 1, 'peaberry': 2, 'premium': 3}\n",
      "[INFO] Split complete ‚Äî Train: 805 (71.4%) | Val: 161 (14.3%) | Test: 161 (14.3%)\n",
      "[INFO] Class distribution per split:\n",
      "[INFO] Split CSVs saved to: /kaggle/working/preprocessed\n",
      "[INFO] ‚úÖ Preprocessing pipeline completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           train  val  test\n",
      "label                      \n",
      "defect       211   43    43\n",
      "longberry    195   39    39\n",
      "peaberry     199   40    39\n",
      "premium      200   39    40\n"
     ]
    }
   ],
   "source": [
    "pipeline = PreprocessingPipeline(config)\n",
    "train_df, val_df, test_df, class_info = pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e33bd7",
   "metadata": {
    "papermill": {
     "duration": 0.004688,
     "end_time": "2026-02-20T07:20:46.964417",
     "exception": false,
     "start_time": "2026-02-20T07:20:46.959729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### üîß Option B ‚Äî Step-by-Step *(Advanced)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ed8397a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T07:20:46.975571Z",
     "iopub.status.busy": "2026-02-20T07:20:46.974916Z",
     "iopub.status.idle": "2026-02-20T07:20:46.979498Z",
     "shell.execute_reply": "2026-02-20T07:20:46.978528Z"
    },
    "papermill": {
     "duration": 0.01261,
     "end_time": "2026-02-20T07:20:46.981542",
     "exception": false,
     "start_time": "2026-02-20T07:20:46.968932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Step 1: Load your own DataFrame ---\n",
    "# df = pd.read_csv(config.metadata_path)\n",
    "\n",
    "# --- Step 2: Remove duplicates ---\n",
    "# detector = DuplicateDetector(config)\n",
    "# df_clean = detector.run(df)\n",
    "# # Or run them separately:\n",
    "# df_no_exact = detector.remove_exact_duplicates(df)\n",
    "# df_clean    = detector.remove_near_duplicates(df_no_exact)\n",
    "\n",
    "# --- Step 3: Encode labels ---\n",
    "# label_proc = LabelProcessor(config)\n",
    "# df_encoded = label_proc.fit_transform(df_clean)\n",
    "# class_info = label_proc.get_class_info()\n",
    "\n",
    "# --- Step 4: Split ---\n",
    "# splitter = DataSplitter(config)\n",
    "# train_df, val_df, test_df = splitter.split(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cffe2d7",
   "metadata": {
    "papermill": {
     "duration": 0.004746,
     "end_time": "2026-02-20T07:20:46.991089",
     "exception": false,
     "start_time": "2026-02-20T07:20:46.986343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## üìä 6. Results Inspection\n",
    "\n",
    "Verifikasi output pipeline sebelum lanjut ke modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469b755a",
   "metadata": {
    "papermill": {
     "duration": 0.004744,
     "end_time": "2026-02-20T07:20:47.000872",
     "exception": false,
     "start_time": "2026-02-20T07:20:46.996128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Split Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1ee18f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T07:20:47.012417Z",
     "iopub.status.busy": "2026-02-20T07:20:47.012101Z",
     "iopub.status.idle": "2026-02-20T07:20:47.019587Z",
     "shell.execute_reply": "2026-02-20T07:20:47.018607Z"
    },
    "papermill": {
     "duration": 0.015829,
     "end_time": "2026-02-20T07:20:47.021754",
     "exception": false,
     "start_time": "2026-02-20T07:20:47.005925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "          SPLIT SUMMARY\n",
      "==========================================\n",
      "  Train :   805 samples  (71.4%)\n",
      "  Val   :   161 samples  (14.3%)\n",
      "  Test  :   161 samples  (14.3%)\n",
      "  Total :  1127 samples\n",
      "\n",
      "==========================================\n",
      "          CLASS INFO\n",
      "==========================================\n",
      "  Num classes : 4\n",
      "  Classes     : ['defect', 'longberry', 'peaberry', 'premium']\n",
      "  Encoding    : {'defect': 0, 'longberry': 1, 'peaberry': 2, 'premium': 3}\n"
     ]
    }
   ],
   "source": [
    "# --- Split summary ---\n",
    "total = len(train_df) + len(val_df) + len(test_df)\n",
    "print(\"=\" * 42)\n",
    "print(\"          SPLIT SUMMARY\")\n",
    "print(\"=\" * 42)\n",
    "print(f\"  Train : {len(train_df):>5} samples  ({len(train_df)/total:.1%})\")\n",
    "print(f\"  Val   : {len(val_df):>5} samples  ({len(val_df)/total:.1%})\")\n",
    "print(f\"  Test  : {len(test_df):>5} samples  ({len(test_df)/total:.1%})\")\n",
    "print(f\"  Total : {total:>5} samples\")\n",
    "print()\n",
    "print(\"=\" * 42)\n",
    "print(\"          CLASS INFO\")\n",
    "print(\"=\" * 42)\n",
    "print(f\"  Num classes : {class_info['num_classes']}\")\n",
    "print(f\"  Classes     : {class_info['class_names']}\")\n",
    "print(f\"  Encoding    : {class_info['class_to_idx']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c98975e",
   "metadata": {
    "papermill": {
     "duration": 0.004811,
     "end_time": "2026-02-20T07:20:47.031241",
     "exception": false,
     "start_time": "2026-02-20T07:20:47.026430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Class Distribution per Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ef6cd20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T07:20:47.042159Z",
     "iopub.status.busy": "2026-02-20T07:20:47.041663Z",
     "iopub.status.idle": "2026-02-20T07:20:47.063358Z",
     "shell.execute_reply": "2026-02-20T07:20:47.062398Z"
    },
    "papermill": {
     "duration": 0.029552,
     "end_time": "2026-02-20T07:20:47.065322",
     "exception": false,
     "start_time": "2026-02-20T07:20:47.035770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution per Split:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>defect</th>\n",
       "      <td>211</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longberry</th>\n",
       "      <td>195</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peaberry</th>\n",
       "      <td>199</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>premium</th>\n",
       "      <td>200</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train  val  test\n",
       "label                      \n",
       "defect       211   43    43\n",
       "longberry    195   39    39\n",
       "peaberry     199   40    39\n",
       "premium      200   39    40"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Class distribution per split ---\n",
    "print(\"Class Distribution per Split:\")\n",
    "dist = pd.DataFrame({\n",
    "    'train': train_df['label'].value_counts(),\n",
    "    'val'  : val_df['label'].value_counts(),\n",
    "    'test' : test_df['label'].value_counts()\n",
    "}).fillna(0).astype(int)\n",
    "display(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f372e3",
   "metadata": {
    "papermill": {
     "duration": 0.004896,
     "end_time": "2026-02-20T07:20:47.075374",
     "exception": false,
     "start_time": "2026-02-20T07:20:47.070478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preview Train DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70836fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T07:20:47.087537Z",
     "iopub.status.busy": "2026-02-20T07:20:47.086755Z",
     "iopub.status.idle": "2026-02-20T07:20:47.098806Z",
     "shell.execute_reply": "2026-02-20T07:20:47.097911Z"
    },
    "papermill": {
     "duration": 0.02001,
     "end_time": "2026-02-20T07:20:47.100542",
     "exception": false,
     "start_time": "2026-02-20T07:20:47.080532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "      <th>md5</th>\n",
       "      <th>phash</th>\n",
       "      <th>phash_group</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/datasets/ardiyanto24/coffee-bean...</td>\n",
       "      <td>defect</td>\n",
       "      <td>8d10ced69c5a51cbaafba5ee4e4adfdf</td>\n",
       "      <td>bec1c12fce3cc831</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/datasets/ardiyanto24/coffee-bean...</td>\n",
       "      <td>defect</td>\n",
       "      <td>930569c68bdd3977e3532552524ef2a9</td>\n",
       "      <td>e7a3986469996665</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/datasets/ardiyanto24/coffee-bean...</td>\n",
       "      <td>defect</td>\n",
       "      <td>aea9bbc373c1c548fe70a84fe82de43a</td>\n",
       "      <td>e1929e6ed9386592</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/datasets/ardiyanto24/coffee-bean...</td>\n",
       "      <td>defect</td>\n",
       "      <td>3c5c0c2cd28968f1838f8dd762ac2b9d</td>\n",
       "      <td>b8e3cd8e66383338</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/datasets/ardiyanto24/coffee-bean...</td>\n",
       "      <td>defect</td>\n",
       "      <td>bf802fd12aeb66eff715609919194a57</td>\n",
       "      <td>b8c6c53bce38319c</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath   label  \\\n",
       "0  /kaggle/input/datasets/ardiyanto24/coffee-bean...  defect   \n",
       "1  /kaggle/input/datasets/ardiyanto24/coffee-bean...  defect   \n",
       "2  /kaggle/input/datasets/ardiyanto24/coffee-bean...  defect   \n",
       "3  /kaggle/input/datasets/ardiyanto24/coffee-bean...  defect   \n",
       "4  /kaggle/input/datasets/ardiyanto24/coffee-bean...  defect   \n",
       "\n",
       "                                md5             phash  phash_group  \\\n",
       "0  8d10ced69c5a51cbaafba5ee4e4adfdf  bec1c12fce3cc831            2   \n",
       "1  930569c68bdd3977e3532552524ef2a9  e7a3986469996665            3   \n",
       "2  aea9bbc373c1c548fe70a84fe82de43a  e1929e6ed9386592            4   \n",
       "3  3c5c0c2cd28968f1838f8dd762ac2b9d  b8e3cd8e66383338            5   \n",
       "4  bf802fd12aeb66eff715609919194a57  b8c6c53bce38319c            6   \n",
       "\n",
       "   encoded_label  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Preview train DataFrame ---\n",
    "print(\"Train DataFrame Preview:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e2255",
   "metadata": {
    "papermill": {
     "duration": 0.004987,
     "end_time": "2026-02-20T07:20:47.110684",
     "exception": false,
     "start_time": "2026-02-20T07:20:47.105697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## üíæ 7. Save Final CSV\n",
    "\n",
    "Simpan CSV final yang hanya berisi `filepath` dan `encoded_label`.\n",
    "File inilah yang akan di-attach ke Notebook 02 sebagai input training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf92326d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T07:20:47.122424Z",
     "iopub.status.busy": "2026-02-20T07:20:47.121657Z",
     "iopub.status.idle": "2026-02-20T07:20:47.138433Z",
     "shell.execute_reply": "2026-02-20T07:20:47.137165Z"
    },
    "papermill": {
     "duration": 0.025005,
     "end_time": "2026-02-20T07:20:47.140543",
     "exception": false,
     "start_time": "2026-02-20T07:20:47.115538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_final.csv saved ‚Äî 805 records\n",
      "val_final.csv saved ‚Äî 161 records\n",
      "test_final.csv saved ‚Äî 161 records\n"
     ]
    }
   ],
   "source": [
    "# --- Save final metadata (filepath + encoded_label only) ---\n",
    "for split_name, split_df in [('train', train_df), ('val', val_df), ('test', test_df)]:\n",
    "    final = split_df[[config.path_col, 'encoded_label']].copy()\n",
    "    final.to_csv(f\"{config.output_dir}/{split_name}_final.csv\", index=False)\n",
    "    print(f\"{split_name}_final.csv saved ‚Äî {len(final)} records\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14738194,
     "datasetId": 8902125,
     "sourceId": 13964761,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 15746367,
     "datasetId": 9522156,
     "sourceId": 14883155,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31286,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37.341118,
   "end_time": "2026-02-20T07:20:47.766128",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-20T07:20:10.425010",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
